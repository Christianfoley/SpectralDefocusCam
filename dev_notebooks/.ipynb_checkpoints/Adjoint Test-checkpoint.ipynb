{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0605e57a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io \n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, glob, cv2\n",
    "\n",
    "# packages needed for making a dataset: \n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from diffuser_utils import *\n",
    "import dataset as ds\n",
    "import models.spectral_model as sm\n",
    "import models.machinelearning_forward as fm\n",
    "\n",
    "from datetime import date, datetime\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from models.unet import Unet\n",
    "import models.unet3d as unet3d\n",
    "\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import dataset_helper_functions.read_pca_data as rpca\n",
    "import csv\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\" #choose the number of gpu that's free. It goes from 0-3\n",
    "\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d34c616d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimize blur False\n"
     ]
    }
   ],
   "source": [
    "# define fwd model\n",
    "mask = load_mask()\n",
    "num_images = 1\n",
    "num_inputs_simult = 3\n",
    "blur_type = 'asymmetric'\n",
    "optimize_blur = False\n",
    "forward_model = fm.Forward_Model(mask, num_ims = num_inputs_simult, blur_type = blur_type, cuda_device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7fb139f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_psf(h):\n",
    "    h_complex = pad_zeros_torch(forward_model,torch.complex(h,torch.zeros_like(h)))\n",
    "    H = torch.fft.fft2(torch.fft.ifftshift(h_complex)).unsqueeze(1)\n",
    "    return H\n",
    "def fft_im(im):\n",
    "    xc = torch.complex(im, torch.zeros_like(im))  \n",
    "    Xi = torch.fft.fft2(xc)    \n",
    "    return Xi\n",
    "def tt(x):\n",
    "    return torch.tensor(x, dtype = torch.float32, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f133fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 30, 512, 512) (1, 2, 256, 256)\n",
      "(2, 3, 256, 256)\n",
      "torch.Size([1, 2, 256, 256]) torch.Size([1, 30, 256, 256])\n",
      "torch.Size([1, 2, 30, 512, 512])\n",
      "torch.Size([1, 2, 30, 512, 512]) torch.Size([3, 1, 512, 512])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-380ac6533ea0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tilda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mx_tilda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mHadj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tilda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/defocam/SpectralDefocusCam/models/machinelearning_forward.py\u001b[0m in \u001b[0;36mHadj\u001b[0;34m(self, sim_meas)\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mSM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfft_im\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#[0].unsqueeze(1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHconj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m         \u001b[0madj_meas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mifft2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHconj\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mSM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0madj_meas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "#x = np.zeros((2, 64, mask.shape[0]*2, mask.shape[1]*2))\n",
    "#x[:,10:20, mask.shape[0], mask.shape[1]]=1\n",
    "\n",
    "x = np.random.randn(2, 30, mask.shape[0]*2, mask.shape[1]*2)\n",
    "y = np.random.randn(1, 2, mask.shape[0], mask.shape[1])\n",
    "#print(x.shape, y.shape)\n",
    "\n",
    "forward_model.Xi = fft_im(tt(x)).unsqueeze(0)\n",
    "forward_model.psfs = forward_model.make_psfs()\n",
    "y_tilda = forward_model.Hfor().detach().cpu().numpy()\n",
    "print('y_tilda shape:',y_tilda.shape)\n",
    "\n",
    "x_tilda = forward_model.Hadj(tt(y)).detach().cpu().numpy()\n",
    "print(x_tilda.shape)\n",
    "\n",
    "print((y.ravel()).dot(y_tilda.ravel()))\n",
    "print((x.ravel()).dot(x_tilda.ravel()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7071b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = forward_model\n",
    "adj = f.Hadj\n",
    "base_x = torch.rand((1, 2, 30, 512, 512))\n",
    "base_y = torch.unsqueeze(torch.rand((2, 256, 256)),0)\n",
    "#base_x = np.random.randn(320*2, 460*2, 64)\n",
    "#base_y = np.random.rand(320,460)\n",
    "\n",
    "y_tilde = f(base_x.to(device)).detach().cpu().numpy()\n",
    "x_tilde = adj(base_y.to(device), f.psf, 1).detach().cpu().numpy()\n",
    "print(y_tilde.shape, x_tilde.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(base_y.shape)\n",
    "x_vector = np.ravel(base_x.detach().cpu().numpy())\n",
    "y_vector = np.ravel(base_y.detach().cpu().numpy())\n",
    "print(y_vector.shape)\n",
    "\n",
    "y_tilde_vector = np.ravel(y_tilde[0])\n",
    "x_tilde_vector = np.ravel(x_tilde)\n",
    "\n",
    "\n",
    "out1 = y_tilde_vector.dot(y_vector)\n",
    "out2 = x_vector.dot(x_tilde_vector)\n",
    "print(out1, out2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93c3dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = forward_model\n",
    "# x and y\n",
    "base_x = torch.rand((30, 512, 512))\n",
    "base_y = torch.unsqueeze(torch.rand((2, 256, 256)),0)\n",
    "x_vector = torch.ravel(base_x).float()\n",
    "y_vector = torch.ravel(base_y)\n",
    "print(y_vector.shape, x_vector.shape)\n",
    "\n",
    "# y~ = Ax and x~ = A'y\n",
    "y_tilde = f(base_x.to(device))[0]\n",
    "x_tilde = f.Hadj(base_y.to(device), f.psf[0][np.newaxis], 1)[0][0]\n",
    "y_tilde_vector = torch.ravel(y_tilde)\n",
    "\n",
    "\n",
    "# y' and x~' = (A'y)'\n",
    "y_transpose = torch.transpose(base_y[0], 1, 2).to(device)\n",
    "x_tilde_transpose = torch.transpose(x_tilde, 1, 2).to(device)\n",
    "\n",
    "x_tilde_transpose_vector = torch.ravel(x_tilde_transpose).float()\n",
    "y_transpose_vector = torch.ravel(y_transpose)\n",
    "print(x_tilde.shape, x_tilde_transpose.shape, x_tilde_transpose_vector.shape)\n",
    "print(base_y.shape, y_transpose.shape)\n",
    "print(y_tilde_vector.shape, y_transpose_vector.shape)\n",
    "\n",
    "# asserting that: y' * y~ = x~' * x\n",
    "print(torch.dot(y_transpose_vector, y_tilde_vector))\n",
    "print(torch.dot(x_tilde_transpose_vector, x_vector.to(device)))\n",
    "#print(result)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "defocam",
   "language": "python",
   "name": "defocam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
