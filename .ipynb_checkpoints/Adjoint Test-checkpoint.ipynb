{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0605e57a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io \n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, glob, cv2\n",
    "\n",
    "# packages needed for making a dataset: \n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from diffuser_utils import *\n",
    "import dataset as ds\n",
    "import models.spectral_model as sm\n",
    "import models.machinelearning_forward as fm\n",
    "\n",
    "from datetime import date, datetime\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from models.unet import Unet\n",
    "import models.unet3d as unet3d\n",
    "\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import dataset_helper_functions.read_pca_data as rpca\n",
    "import csv\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]= \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"3\" #choose the number of gpu that's free. It goes from 0-3\n",
    "\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d34c616d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimize blur False\n"
     ]
    }
   ],
   "source": [
    "# define fwd model\n",
    "mask = load_mask()\n",
    "num_images = 1\n",
    "num_inputs_simult = 2\n",
    "blur_type = 'asymmetric'\n",
    "optimize_blur = False\n",
    "forward_model = fm.Forward_Model(mask, num_ims = num_inputs_simult, blur_type = blur_type, cuda_device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7071b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 256, 256])\n",
      "(1, 2, 256, 256) (1, 2, 30, 512, 512)\n",
      "torch.Size([1, 2, 256, 256])\n",
      "(131072,)\n",
      "20.107943 10325.98614722865\n"
     ]
    }
   ],
   "source": [
    "f = forward_model\n",
    "adj = f.Hadj\n",
    "base_x = torch.rand((1, 2, 30, 512, 512))\n",
    "base_y = torch.unsqueeze(torch.rand((2, 256, 256)),0)\n",
    "#base_x = np.random.randn(320*2, 460*2, 64)\n",
    "#base_y = np.random.rand(320,460)\n",
    "\n",
    "y_tilde = f(base_x.to(device)).detach().cpu().numpy()\n",
    "x_tilde = adj(base_y.to(device), f.psf, 1).detach().cpu().numpy()\n",
    "print(y_tilde.shape, x_tilde.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(base_y.shape)\n",
    "x_vector = np.ravel(base_x.detach().cpu().numpy())\n",
    "y_vector = np.ravel(base_y.detach().cpu().numpy())\n",
    "print(y_vector.shape)\n",
    "\n",
    "y_tilde_vector = np.ravel(y_tilde[0])\n",
    "x_tilde_vector = np.ravel(x_tilde)\n",
    "\n",
    "\n",
    "out1 = y_tilde_vector.dot(y_vector)\n",
    "out2 = x_vector.dot(x_tilde_vector)\n",
    "print(out1, out2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d93c3dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([131072]) torch.Size([7864320])\n",
      "torch.Size([30, 512, 512]) torch.Size([30, 512, 512]) torch.Size([7864320])\n",
      "torch.Size([1, 2, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([131072]) torch.Size([131072])\n",
      "tensor(20.1736, device='cuda:0', grad_fn=<DotBackward>)\n",
      "tensor(7.2174e-07, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "f = forward_model\n",
    "# x and y\n",
    "base_x = torch.rand((30, 512, 512))\n",
    "base_y = torch.unsqueeze(torch.rand((2, 256, 256)),0)\n",
    "x_vector = torch.ravel(base_x)\n",
    "y_vector = torch.ravel(base_y)\n",
    "print(y_vector.shape, x_vector.shape)\n",
    "\n",
    "# y~ = Ax and x~ = A'y\n",
    "y_tilde = f(base_x.to(device))[0]\n",
    "x_tilde = f.Hadj(base_y.to(device), f.psf[0][np.newaxis], 1)[0][0]\n",
    "y_tilde_vector = torch.ravel(y_tilde)\n",
    "\n",
    "\n",
    "# y' and x~' = (A'y)'\n",
    "y_transpose = torch.transpose(base_y[0], 1, 2).to(device)\n",
    "x_tilde_transpose = torch.transpose(x_tilde, 1, 2).to(device)\n",
    "\n",
    "x_tilde_transpose_vector = torch.ravel(x_tilde_transpose)\n",
    "y_transpose_vector = torch.ravel(y_transpose)\n",
    "print(x_tilde.shape, x_tilde_transpose.shape, x_tilde_transpose_vector.shape)\n",
    "print(base_y.shape, y_transpose.shape)\n",
    "print(y_tilde_vector.shape, y_transpose_vector.shape)\n",
    "\n",
    "# asserting that: y' * y~ = x~' * x\n",
    "print(torch.dot(y_transpose_vector, y_tilde_vector))\n",
    "print(torch.dot(x_tilde_transpose_vector, x_vector.to(device)))\n",
    "#print(result)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "defocam",
   "language": "python",
   "name": "defocam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
