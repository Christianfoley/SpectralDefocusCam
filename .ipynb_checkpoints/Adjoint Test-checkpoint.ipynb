{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0605e57a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io \n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, glob, cv2\n",
    "\n",
    "# packages needed for making a dataset: \n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "from diffuser_utils import *\n",
    "import dataset as ds\n",
    "import models.spectral_model as sm\n",
    "import models.machinelearning_forward as fm\n",
    "\n",
    "from datetime import date, datetime\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from models.unet import Unet\n",
    "import models.unet3d as unet3d\n",
    "\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import dataset_helper_functions.read_pca_data as rpca\n",
    "import csv\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]= \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"3\" #choose the number of gpu that's free. It goes from 0-3\n",
    "\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d34c616d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimize blur False\n"
     ]
    }
   ],
   "source": [
    "# define fwd model\n",
    "mask = load_mask()\n",
    "num_images = 1\n",
    "num_inputs_simult = 2\n",
    "blur_type = 'asymmetric'\n",
    "optimize_blur = False\n",
    "forward_model = fm.Forward_Model(mask, num_ims = num_inputs_simult, blur_type = blur_type, cuda_device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7071b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 2, 256, 256])\n",
      "(1, 2, 256, 256) (1, 2, 30, 512, 512)\n",
      "torch.Size([1, 2, 256, 256])\n",
      "(131072,)\n",
      "20.039211 10306.204522276244\n"
     ]
    }
   ],
   "source": [
    "f = forward_model\n",
    "adj = f.Hadj\n",
    "base_x = torch.rand((1, 2, 30, 512, 512))\n",
    "base_y = torch.unsqueeze(torch.rand((2, 256, 256)),0)\n",
    "#base_x = np.random.randn(320*2, 460*2, 64)\n",
    "#base_y = np.random.rand(320,460)\n",
    "\n",
    "y_tilde = f(base_x.to(device)).detach().cpu().numpy()\n",
    "x_tilde = adj(base_y.to(device), f.psf, 1).detach().cpu().numpy()\n",
    "print(y_tilde.shape, x_tilde.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(base_y.shape)\n",
    "x_vector = np.ravel(base_x.detach().cpu().numpy())\n",
    "y_vector = np.ravel(base_y.detach().cpu().numpy())\n",
    "print(y_vector.shape)\n",
    "\n",
    "y_tilde_vector = np.ravel(y_tilde[0])\n",
    "x_tilde_vector = np.ravel(x_tilde)\n",
    "\n",
    "\n",
    "out1 = y_tilde_vector.dot(y_vector)\n",
    "out2 = x_vector.dot(x_tilde_vector)\n",
    "print(out1, out2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d93c3dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([131072]) torch.Size([7864320])\n",
      "torch.Size([30, 512, 512]) torch.Size([1, 512, 512])\n",
      "torch.Size([30, 512])\n",
      "torch.Size([30, 512, 512]) torch.Size([1, 512, 512])\n",
      "torch.Size([30, 512])\n",
      "torch.Size([1, 2, 256, 256])\n",
      "torch.Size([30, 512, 512]) torch.Size([30, 512, 512]) torch.Size([7864320])\n",
      "torch.Size([1, 2, 256, 256]) torch.Size([2, 256, 256])\n",
      "torch.Size([131072]) torch.Size([131072])\n",
      "tensor(20.0450, device='cuda:0', grad_fn=<DotBackward>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "dot : expected both vectors to have same dtype, but found Double and Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-7b9c908423d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# asserting that: y' * y~ = x~' * x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_transpose_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tilde_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tilde_transpose_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;31m#print(result)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: dot : expected both vectors to have same dtype, but found Double and Float"
     ]
    }
   ],
   "source": [
    "f = forward_model\n",
    "# x and y\n",
    "base_x = torch.rand((30, 512, 512))\n",
    "base_y = torch.unsqueeze(torch.rand((2, 256, 256)),0)\n",
    "x_vector = torch.ravel(base_x).float()\n",
    "y_vector = torch.ravel(base_y)\n",
    "print(y_vector.shape, x_vector.shape)\n",
    "\n",
    "# y~ = Ax and x~ = A'y\n",
    "y_tilde = f(base_x.to(device))[0]\n",
    "x_tilde = f.Hadj(base_y.to(device), f.psf[0][np.newaxis], 1)[0][0]\n",
    "y_tilde_vector = torch.ravel(y_tilde)\n",
    "\n",
    "\n",
    "# y' and x~' = (A'y)'\n",
    "y_transpose = torch.transpose(base_y[0], 1, 2).to(device)\n",
    "x_tilde_transpose = torch.transpose(x_tilde, 1, 2).to(device)\n",
    "\n",
    "x_tilde_transpose_vector = torch.ravel(x_tilde_transpose).float()\n",
    "y_transpose_vector = torch.ravel(y_transpose)\n",
    "print(x_tilde.shape, x_tilde_transpose.shape, x_tilde_transpose_vector.shape)\n",
    "print(base_y.shape, y_transpose.shape)\n",
    "print(y_tilde_vector.shape, y_transpose_vector.shape)\n",
    "\n",
    "# asserting that: y' * y~ = x~' * x\n",
    "print(torch.dot(y_transpose_vector, y_tilde_vector))\n",
    "print(torch.dot(x_tilde_transpose_vector, x_vector.to(device)))\n",
    "#print(result)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "defocam",
   "language": "python",
   "name": "defocam"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
