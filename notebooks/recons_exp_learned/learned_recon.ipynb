{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import os, sys, glob, copy, json\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import convolve\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image as Image\n",
    "import pathlib\n",
    "sys.path.insert(0, \"/home/cfoley_waller/defocam/SpectralDefocusCam\")\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "\n",
    "\n",
    "sys.path.insert(0, \"../..\")\n",
    "import train\n",
    "import utils.helper_functions as helper\n",
    "import utils.diffuser_utils as diffuser_utils\n",
    "import dataset.precomp_dataset as ds\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(trained_weights_path, device):\n",
    "    config_path = os.path.join(pathlib.Path(trained_weights_path).parent, \"training_config.yml\")\n",
    "\n",
    "    config = helper.read_config(config_path)\n",
    "    config[\"device\"] = device\n",
    "    config[\"forward_model_params\"][\"operations\"]['adj_mask_noise'] = False\n",
    "    config[\"forward_model_params\"][\"operations\"]['fwd_mask_noise'] = False\n",
    "    config[\"data_precomputed\"] = False\n",
    "    config[\"preload_weights\"] = True\n",
    "    config[\"checkpoint_dir\"] = trained_weights_path\n",
    "\n",
    "    device = torch.device(config['device'])\n",
    "    model = train.get_model(config=config, device=device)   \n",
    "    model.eval()\n",
    "\n",
    "    print(f\"Model using: {device}\")\n",
    "    return model, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda:1'\n",
    "trained_weights_path = \"/home/cfoley/defocuscamdata/models/checkpoint_results_learned_largecrop_firstlast_3_config.yml/2024_03_21_21_45_46/saved_model_ep60_testloss_0.053416458687380604.pt\"\n",
    "model_stack_depth = 3\n",
    "model, config = load_model(trained_weights_path, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expermental prediction indoors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_exp_meas(meas, config):\n",
    "    # read\n",
    "    center = config[\"image_center\"]\n",
    "    dimy, dimx = config[\"patch_crop\"]\n",
    "    crop = lambda x: x[center[0] -dimy//2:center[0]+dimy//2, center[1]-dimx//2: center[1]+dimx//2]\n",
    "    meas =  crop(np.array(Image.open(meas), dtype=float))\n",
    "\n",
    "    # downsample\n",
    "    meas = diffuser_utils.pyramid_down(meas, config[\"patch_size\"])\n",
    "\n",
    "    return meas\n",
    "\n",
    "def get_plot_meas(exp_meas_path, config, stack_depth = model_stack_depth):\n",
    "    exp_meas = [preprocess_exp_meas(m, config) for m in sorted(glob.glob(os.path.join(exp_meas_path, \"*.bmp\")))]#[0::4]\n",
    "\n",
    "    # sample defocus\n",
    "    if stack_depth == 2:\n",
    "        exp_meas = exp_meas[0::4]\n",
    "    elif stack_depth == 3:\n",
    "        exp_meas = exp_meas[0::2]\n",
    "    elif stack_depth == 5:\n",
    "        exp_meas = exp_meas\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Only 2, 3, and 5 meas models supported: {len(exp_meas)}\")\n",
    "    \n",
    "    fig, ax = plt.subplots(1, len(exp_meas), figsize = (4*len(exp_meas), 4))\n",
    "    fig.set_dpi(180)\n",
    "    for i, meas in enumerate(exp_meas):\n",
    "        ax[i].imshow(exp_meas[i], cmap='gray')\n",
    "        ax[i].set_title(f\"Focus level: {i}\")\n",
    "        ax[i].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    return exp_meas\n",
    "\n",
    "def predict(exp_meas, recon_model):\n",
    "    norm = ds.Normalize(0,1)\n",
    "    exp_meas_stack = norm(torch.tensor(np.stack(exp_meas)).to(device)[None, :, None, ...])\n",
    "    print(f\"mean {exp_meas_stack.mean()} - std {exp_meas_stack.std()} - shape {exp_meas_stack.shape}\")\n",
    "    \n",
    "    pred = recon_model(exp_meas_stack)[0].detach().cpu().numpy().transpose(1,2,0)\n",
    "    return helper.value_norm(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_meas_path = \"/home/cfoley/defocuscamdata/calibration_data/DMM_37UX178_ML_calib_data/03_07/exp_meas/usaf_negative\"\n",
    "p = predict(get_plot_meas(exp_meas_path, config), model.model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling = (1.1, 0.9, 0.7)\n",
    "im = Image.fromarray((helper.value_norm(helper.select_and_average_bands(p, fc_range=(390,870), scaling=scaling))*255).astype(np.uint8))\n",
    "\n",
    "np.save(os.path.join(\"/home/cfoley/defocuscamdata/recons/exp_results_figure/\", \"_\".join([os.path.basename(trained_weights_path)[:-3], os.path.basename(exp_meas_path)])), p)\n",
    "im.save(os.path.join(\"/home/cfoley/defocuscamdata/recons/exp_results_figure/\", \"_\".join([os.path.basename(trained_weights_path)[:-3], os.path.basename(exp_meas_path), f\"largecrop_scaling-{scaling}\" + \".png\"])))\n",
    "\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_meas_path = \"/home/cfoley/defocuscamdata/calibration_data/DMM_37UX178_ML_calib_data/03_07/exp_meas/color_palette\"\n",
    "p = predict(get_plot_meas(exp_meas_path, config), model.model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling = (1.1, 0.8, 0.65)\n",
    "im = Image.fromarray((helper.value_norm(helper.select_and_average_bands(p, fc_range=(390,870), scaling=scaling))*255).astype(np.uint8))\n",
    "\n",
    "np.save(os.path.join(\"/home/cfoley/defocuscamdata/recons/exp_results_figure/\", \"_\".join([os.path.basename(trained_weights_path)[:-3], os.path.basename(exp_meas_path)])), p)\n",
    "im.save(os.path.join(\"/home/cfoley/defocuscamdata/recons/exp_results_figure/\", \"_\".join([os.path.basename(trained_weights_path)[:-3], os.path.basename(exp_meas_path), f\"largecrop_scaling-{scaling}\" + \".png\"])))\n",
    "\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_meas_path = \"/home/cfoley/defocuscamdata/calibration_data/DMM_37UX178_ML_calib_data/03_07/exp_meas/mushroom_knife\"\n",
    "p = predict(get_plot_meas(exp_meas_path, config), model.model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "white = np.maximum(0.4, np.mean(p[291-3:291+3, 463-3:463+3, :], axis=(0,1)))\n",
    "white_balanced = p / white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling = (1.1, 0.8, 0.85)\n",
    "im = Image.fromarray((helper.value_norm(helper.select_and_average_bands(white_balanced, fc_range=(390,870), scaling=scaling))*255).astype(np.uint8))\n",
    "\n",
    "np.save(os.path.join(\"/home/cfoley/defocuscamdata/recons/exp_results_figure/\", \"_\".join([os.path.basename(trained_weights_path)[:-3], os.path.basename(exp_meas_path)])), white_balanced)\n",
    "im.save(os.path.join(\"/home/cfoley/defocuscamdata/recons/exp_results_figure/\", \"_\".join([os.path.basename(trained_weights_path)[:-3], os.path.basename(exp_meas_path), f\"largecrop_scaling-{scaling}\" + \".png\"])))\n",
    "\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_meas_path = \"/home/cfoley/defocuscamdata/calibration_data/DMM_37UX178_ML_calib_data/11_21/exp_meas/duckincar\"\n",
    "p = predict(get_plot_meas(exp_meas_path, config), model.model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.clip(p, 0, np.quantile(p, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling = (1.15, 0.9, 0.8)\n",
    "im = Image.fromarray((helper.value_norm(helper.select_and_average_bands(p, fc_range=(390,870), scaling=scaling))*255).astype(np.uint8))\n",
    "\n",
    "np.save(os.path.join(\"/home/cfoley/defocuscamdata/recons/exp_results_figure/\", \"_\".join([os.path.basename(trained_weights_path)[:-3], os.path.basename(exp_meas_path)])), p)\n",
    "im.save(os.path.join(\"/home/cfoley/defocuscamdata/recons/exp_results_figure/\", \"_\".join([os.path.basename(trained_weights_path)[:-3], os.path.basename(exp_meas_path), f\"largecrop_scaling-{scaling}\" + \".png\"])))\n",
    "\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_meas_path = \"/home/cfoley/defocuscamdata/calibration_data/DMM_37UX178_ML_calib_data/03_07/exp_meas/rubberband_cards\"\n",
    "p = predict(get_plot_meas(exp_meas_path, config), model.model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling = (1.2, 0.9, 0.75)\n",
    "im = Image.fromarray((helper.value_norm(helper.select_and_average_bands(p, fc_range=(390,870), scaling=scaling))*255).astype(np.uint8))\n",
    "\n",
    "np.save(os.path.join(\"/home/cfoley/defocuscamdata/recons/exp_results_figure/\", \"_\".join([os.path.basename(trained_weights_path)[:-3], os.path.basename(exp_meas_path)])), p)\n",
    "im.save(os.path.join(\"/home/cfoley/defocuscamdata/recons/exp_results_figure/\", \"_\".join([os.path.basename(trained_weights_path)[:-3], os.path.basename(exp_meas_path), f\"largecrop_scaling-{scaling}\" + \".png\"])))\n",
    "\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_meas_path = \"/home/cfoley/defocuscamdata/calibration_data/DMM_37UX178_ML_calib_data/03_07/exp_meas/origami_stars_colorful\"\n",
    "p = predict(get_plot_meas(exp_meas_path, config), model.model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped = np.clip(p, 0, np.quantile(p, 0.9999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling = (1.2, 0.9, 0.7)\n",
    "im = Image.fromarray((helper.value_norm(helper.select_and_average_bands(clipped, fc_range=(390,870), scaling=scaling))*255).astype(np.uint8))\n",
    "\n",
    "np.save(os.path.join(\"/home/cfoley/defocuscamdata/recons/exp_results_figure/\", \"_\".join([os.path.basename(trained_weights_path)[:-3], os.path.basename(exp_meas_path)])), p)\n",
    "im.save(os.path.join(\"/home/cfoley/defocuscamdata/recons/exp_results_figure/\", \"_\".join([os.path.basename(trained_weights_path)[:-3], os.path.basename(exp_meas_path), f\"largecrop_scaling-{scaling}\" + \".png\"])))\n",
    "\n",
    "im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outside scenes success cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_weights_path_2meas = \"/home/cfoley/defocuscamdata/models/checkpoint_results_learned_largecrop_config.yml/2024_03_16_21_09_51/saved_model_ep49_testloss_0.05782177185882693.pt\"\n",
    "model_2meas, config_2meas = load_model(trained_weights_path_2meas, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_meas_path = \"/home/cfoley/defocuscamdata/calibration_data/DMM_37UX178_ML_calib_data/3_19/outside_one\"\n",
    "p = predict(get_plot_meas(exp_meas_path, config_2meas, stack_depth=5), model_2meas.model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling = (1.3,0.85,1)\n",
    "im = Image.fromarray((helper.value_norm(helper.select_and_average_bands(p, fc_range=(390,870), scaling=scaling))*255).astype(np.uint8))\n",
    "\n",
    "np.save(os.path.join(\"/home/cfoley/defocuscamdata/recons/exp_results_figure/\", \"_\".join([os.path.basename(trained_weights_path_2meas)[:-3], os.path.basename(exp_meas_path)])), p)\n",
    "im.save(os.path.join(\"/home/cfoley/defocuscamdata/recons/exp_results_figure/\", \"_\".join([os.path.basename(trained_weights_path_2meas)[:-3], os.path.basename(exp_meas_path), f\"largecrop_scaling-{scaling}\" + \".png\"])))\n",
    "\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_meas_path = \"/home/cfoley/defocuscamdata/calibration_data/DMM_37UX178_ML_calib_data/3_19/outside_six\"\n",
    "p = predict(get_plot_meas(exp_meas_path, config), model.model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling = (1.1, 0.75, 0.75)\n",
    "im = Image.fromarray((helper.value_norm(helper.select_and_average_bands(p, fc_range=(390,870), scaling=scaling))*255).astype(np.uint8))\n",
    "\n",
    "np.save(os.path.join(\"/home/cfoley/defocuscamdata/recons/exp_results_figure/\", \"_\".join([os.path.basename(trained_weights_path)[:-3], os.path.basename(exp_meas_path)])), p)\n",
    "im.save(os.path.join(\"/home/cfoley/defocuscamdata/recons/exp_results_figure/\", \"_\".join([os.path.basename(trained_weights_path)[:-3], os.path.basename(exp_meas_path), f\"largecrop_scaling-{scaling}\" + \".png\"])))\n",
    "\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_meas_path = \"/home/cfoley/defocuscamdata/calibration_data/DMM_37UX178_ML_calib_data/3_19/outside_eight2\"\n",
    "p = predict(get_plot_meas(exp_meas_path, config), model.model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling = (1, 0.9, 0.95)\n",
    "im = Image.fromarray((helper.value_norm(helper.select_and_average_bands(p, fc_range=(390,870), scaling=scaling))*255).astype(np.uint8))\n",
    "\n",
    "np.save(os.path.join(\"/home/cfoley/defocuscamdata/recons/exp_results_figure/\", \"_\".join([os.path.basename(trained_weights_path)[:-3], os.path.basename(exp_meas_path)])), p)\n",
    "im.save(os.path.join(\"/home/cfoley/defocuscamdata/recons/exp_results_figure/\", \"_\".join([os.path.basename(trained_weights_path)[:-3], os.path.basename(exp_meas_path), f\"largecrop_scaling-{scaling}\" + \".png\"])))\n",
    "\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_meas_path = \"/home/cfoley/defocuscamdata/calibration_data/DMM_37UX178_ML_calib_data/3_19/outside_nine2\"\n",
    "p = predict(get_plot_meas(exp_meas_path, config), model.model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling = (1, 0.8, 0.75)\n",
    "im = Image.fromarray((helper.value_norm(helper.select_and_average_bands(p, fc_range=(390,870), scaling=scaling))*255).astype(np.uint8))\n",
    "\n",
    "np.save(os.path.join(\"/home/cfoley/defocuscamdata/recons/exp_results_figure/\", \"_\".join([os.path.basename(trained_weights_path)[:-3], os.path.basename(exp_meas_path)])), p)\n",
    "im.save(os.path.join(\"/home/cfoley/defocuscamdata/recons/exp_results_figure/\", \"_\".join([os.path.basename(trained_weights_path)[:-3], os.path.basename(exp_meas_path), f\"largecrop_scaling-{scaling}\" + \".png\"])))\n",
    "\n",
    "im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Failure cases - unstable camera position or movement in the scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_meas_path = \"/home/cfoley/defocuscamdata/calibration_data/DMM_37UX178_ML_calib_data/3_19/outside_ten\"\n",
    "p = predict(get_plot_meas(exp_meas_path, config), model.model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling = (1, 0.8, 0.75)\n",
    "im = Image.fromarray((helper.value_norm(helper.select_and_average_bands(p, fc_range=(390,870), scaling=scaling))*255).astype(np.uint8))\n",
    "\n",
    "np.save(os.path.join(\"/home/cfoley/defocuscamdata/recons/exp_results_figure/\", \"_\".join([os.path.basename(trained_weights_path)[:-3], os.path.basename(exp_meas_path)])), p)\n",
    "im.save(os.path.join(\"/home/cfoley/defocuscamdata/recons/exp_results_figure/\", \"_\".join([os.path.basename(trained_weights_path)[:-3], os.path.basename(exp_meas_path), f\"largecrop_scaling-{scaling}\" + \".png\"])))\n",
    "\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_meas_path = \"/home/cfoley/defocuscamdata/calibration_data/DMM_37UX178_ML_calib_data/3_19/outside_seven\"\n",
    "p = predict(get_plot_meas(exp_meas_path, config), model.model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling = (1, 0.8, 0.75)\n",
    "im = Image.fromarray((helper.value_norm(helper.select_and_average_bands(p, fc_range=(390,870), scaling=scaling))*255).astype(np.uint8))\n",
    "\n",
    "np.save(os.path.join(\"/home/cfoley/defocuscamdata/recons/exp_results_figure/\", \"_\".join([os.path.basename(trained_weights_path)[:-3], os.path.basename(exp_meas_path)])), p)\n",
    "im.save(os.path.join(\"/home/cfoley/defocuscamdata/recons/exp_results_figure/\", \"_\".join([os.path.basename(trained_weights_path)[:-3], os.path.basename(exp_meas_path), f\"largecrop_scaling-{scaling}\" + \".png\"])))\n",
    "\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_meas_path = \"/home/cfoley/defocuscamdata/calibration_data/DMM_37UX178_ML_calib_data/3_19/outside_eleven\"\n",
    "p = predict(get_plot_meas(exp_meas_path, config), model.model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = p[371, 231, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling = (1, 0.75, 0.9)\n",
    "im = Image.fromarray((helper.value_norm(helper.select_and_average_bands(p - bias, fc_range=(390,870), scaling=scaling))*255).astype(np.uint8))\n",
    "\n",
    "np.save(os.path.join(\"/home/cfoley/defocuscamdata/recons/exp_results_figure/\", \"_\".join([os.path.basename(trained_weights_path)[:-3], os.path.basename(exp_meas_path)])), p)\n",
    "im.save(os.path.join(\"/home/cfoley/defocuscamdata/recons/exp_results_figure/\", \"_\".join([os.path.basename(trained_weights_path)[:-3], os.path.basename(exp_meas_path), f\"largecrop_scaling-{scaling}\" + \".png\"])))\n",
    "\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_meas_path = \"/home/cfoley/defocuscamdata/calibration_data/DMM_37UX178_ML_calib_data/3_19/outside_three\"\n",
    "p = predict(get_plot_meas(exp_meas_path, config_2meas), model_2meas.model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling = (1, 0.7, 0.7)\n",
    "im = Image.fromarray((helper.value_norm(helper.select_and_average_bands(p, fc_range=(390,870), scaling=scaling))*255).astype(np.uint8))\n",
    "\n",
    "np.save(os.path.join(\"/home/cfoley/defocuscamdata/recons/exp_results_figure/\", \"_\".join([os.path.basename(trained_weights_path)[:-3], os.path.basename(exp_meas_path)])), p)\n",
    "im.save(os.path.join(\"/home/cfoley/defocuscamdata/recons/exp_results_figure/\", \"_\".join([os.path.basename(trained_weights_path)[:-3], os.path.basename(exp_meas_path), f\"largecrop_scaling-{scaling}\" + \".png\"])))\n",
    "\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_meas_path = \"/home/cfoley/defocuscamdata/calibration_data/DMM_37UX178_ML_calib_data/3_19/outside_two\"\n",
    "p = predict(get_plot_meas(exp_meas_path, config_2meas), model_2meas.model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling = (1, 0.7, 0.7)\n",
    "im = Image.fromarray((helper.value_norm(helper.select_and_average_bands(p, fc_range=(390,870), scaling=scaling))*255).astype(np.uint8))\n",
    "\n",
    "np.save(os.path.join(\"/home/cfoley/defocuscamdata/recons/exp_results_figure/\", \"_\".join([os.path.basename(trained_weights_path)[:-3], os.path.basename(exp_meas_path)])), p)\n",
    "im.save(os.path.join(\"/home/cfoley/defocuscamdata/recons/exp_results_figure/\", \"_\".join([os.path.basename(trained_weights_path)[:-3], os.path.basename(exp_meas_path), f\"largecrop_scaling-{scaling}\" + \".png\"])))\n",
    "\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchjax_310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
