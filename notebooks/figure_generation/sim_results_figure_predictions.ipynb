{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, torch, scipy.io as io, glob, os, OpenEXR, matplotlib.pyplot as plt, h5py, PIL.Image as Image, pathlib\n",
    "import sys\n",
    "sys.path.insert(0, \"../..\")\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "device = \"cuda:1\"\n",
    "\n",
    "import utils.helper_functions as helper\n",
    "import utils.diffuser_utils as diffuser_utils\n",
    "import dataset.preprocess_data as prep_data\n",
    "import train\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "SAVE_GT_PATH = \"/home/cfoley/defocuscamdata/recons/sim_comparison_figure/model_input_gts\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#harvard_bookshelf = \"/home/cfoley/defocuscamdata/recons/sim_comparison_figure/sample_data_preprocessed/imgh2_patch_0.mat\"\n",
    "harvard_bushes = \"/home/cfoley/defocuscamdata/recons/sim_comparison_figure/sample_data_preprocessed/imgf8_patch_0.mat\"\n",
    "kaist_img = \"/home/cfoley/defocuscamdata/sample_data/kaistdata/scene03_reflectance.mat\"\n",
    "fruit_artichoke = \"/home/cfoley/defocuscamdata/sample_data/fruitdata/pca/internals_artichoke_SegmentedCroppedCompressed.mat\"\n",
    "icvl_color_checker = \"/home/cfoley/defocuscamdata/sample_data/icvldata/IDS_COLORCHECK_1020-1223.mat\"\n",
    "\n",
    "icvl_color_checker = prep_data.project_spectral(np.asarray(h5py.File(icvl_color_checker)['rad']).transpose(1,2,0)[::-1, ::-1], 30)[300:820, 200:820]\n",
    "kaist_img = prep_data.project_spectral(io.loadmat(kaist_img)['ref'][300:300+420*5, 200:200+620*5], 30)\n",
    "harvard_bushes = io.loadmat(harvard_bushes)['image']\n",
    "fruit_artichoke = prep_data.project_spectral(prep_data.read_compressed(io.loadmat(fruit_artichoke)), 30).transpose(1,0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_fc(img, fc_range=(420,720)):\n",
    "    plt.figure(dpi=100)\n",
    "    rgbimg = helper.select_and_average_bands(img, fc_range=fc_range)\n",
    "    plt.imshow(rgbimg / np.max(rgbimg))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_fc(icvl_color_checker), show_fc(fruit_artichoke, fc_range=(400,780)), show_fc(harvard_bushes), show_fc(kaist_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_image(image, crop_shape, patch_shape):\n",
    "    # 0 1 normalize\n",
    "    image = np.stack(\n",
    "        [diffuser_utils.pyramid_down(image[:crop_shape[0],:crop_shape[1],i],patch_shape) for i in range(image.shape[-1])], 0\n",
    "    )\n",
    "\n",
    "    image = (image - max(0., np.min(image)))\n",
    "    image = image / np.max(image)\n",
    "    image = torch.tensor(image)[None, None,...]\n",
    "    return image\n",
    "\n",
    "def save_image_fc_npy(image, savename, fc_range=(420,720)):\n",
    "    print(\"Saving: \", savename + \".npy\")\n",
    "    np.save(savename + \".npy\", image)\n",
    "\n",
    "    print(\"Saving fc: \", savename + \".png\")\n",
    "    fc_img = helper.select_and_average_bands(image, fc_range=fc_range)\n",
    "    fc_img = Image.fromarray(((fc_img / fc_img.max())*255).astype(np.uint8))\n",
    "    fc_img.save(savename + \".png\")\n",
    "    return fc_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all the ground truths\n",
    "harvard_bushes_gt_name = os.path.join(SAVE_GT_PATH, \"harvard_bushes_gt\")\n",
    "fruit_artichoke_gt_name = os.path.join(SAVE_GT_PATH, \"fruit_artichoke_gt\")\n",
    "icvl_color_checker_gt_name = os.path.join(SAVE_GT_PATH, \"icvl_color_checker_gt\")\n",
    "kaist_img_gt_name = os.path.join(SAVE_GT_PATH, \"kaist_scene03_gt\")\n",
    "\n",
    "harvard_bushes_gt = prep_image(harvard_bushes, harvard_bushes.shape[:2], (420,620))\n",
    "fruit_artichoke_gt = prep_image(fruit_artichoke, fruit_artichoke.shape[:2], (420,620))\n",
    "icvl_color_checker_gt = prep_image(icvl_color_checker, icvl_color_checker.shape[:2], (420,620))\n",
    "kaist_img_gt = prep_image(kaist_img, kaist_img.shape[:2], (420,620))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_image_fc_npy(harvard_bushes_gt[0,0].numpy().transpose(1,2,0), harvard_bushes_gt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_image_fc_npy(fruit_artichoke_gt[0,0].numpy().transpose(1,2,0), fruit_artichoke_gt_name, fc_range=(400,780))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_image_fc_npy(icvl_color_checker_gt[0,0].numpy().transpose(1,2,0), icvl_color_checker_gt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_image_fc_npy(kaist_img_gt[0,0].numpy().transpose(1,2,0), kaist_img_gt_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FISTA RECONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fista_config = \"/home/cfoley/SpectralDefocusCam/notebooks/recons_sim_fista/fista_config_static.yml\"\n",
    "config = helper.read_config(fista_config)\n",
    "model = train.get_model(config, device=device)\n",
    "fm, rm = model.model1, model.model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = fm(harvard_bushes_gt.to(device))\n",
    "rm(sim.squeeze(dim=(0,2)))\n",
    "recon = rm.out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savename = os.path.join(config[\"save_recon_path\"], f\"harvard_bushes_fista_recon_{rm.psfs.shape[0]}_{rm.tv_lambda}_{rm.tv_lambdaw}_{rm.tv_lambdax}\")\n",
    "save_image_fc_npy(recon, savename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = fm(fruit_artichoke_gt.to(device))\n",
    "rm(sim.squeeze(dim=(0,2)))\n",
    "recon = rm.out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savename = os.path.join(config[\"save_recon_path\"], f\"fruit_artichoke_fista_recon_{rm.psfs.shape[0]}_{rm.tv_lambda}_{rm.tv_lambdaw}_{rm.tv_lambdax}\")\n",
    "save_image_fc_npy(recon, savename, fc_range=(400,780))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = fm(icvl_color_checker_gt.to(device))\n",
    "rm(sim.squeeze(dim=(0,2)))\n",
    "recon = rm.out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savename = os.path.join(config[\"save_recon_path\"], f\"icvl_colorpalette_fista_recon_{rm.psfs.shape[0]}_{rm.tv_lambda}_{rm.tv_lambdaw}_{rm.tv_lambdax}\")\n",
    "save_image_fc_npy(recon, savename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = fm(kaist_img_gt.to(device))\n",
    "rm(sim.squeeze(dim=(0,2)))\n",
    "recon = rm.out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savename = os.path.join(config[\"save_recon_path\"], f\"kaist_scene03_fista_recon_{rm.psfs.shape[0]}_{rm.tv_lambda}_{rm.tv_lambdaw}_{rm.tv_lambdax}\")\n",
    "save_image_fc_npy(recon, savename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEARNED RECONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import overlap_stitch as stitch_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trained_weights_path = \"/home/cfoley/defocuscamdata/models/checkpoint_train_02_07_2024_lsi_adjoint_condunet_L1psf_2meas.yml/2024_03_11_14_44_55/saved_model_ep28_testloss_0.04970918206568315.pt\"\n",
    "trained_weights_path = \"/home/cfoley/defocuscamdata/models/checkpoint_train_02_07_2024_lsi_adjoint_condunet_firstlastonly_L1psf_3meas.yml/2024_03_20_00_38_33/saved_model_ep68_testloss_0.039786975884608014.pt\"\n",
    "learned_config = os.path.join(pathlib.Path(trained_weights_path).parent, \"training_config.yml\")\n",
    "\n",
    "config = helper.read_config(learned_config)\n",
    "config[\"save_recon_path\"] = \"/home/cfoley/defocuscamdata/recons/sim_comparison_figure/learned_recons\"\n",
    "config['data_precomputed'] = False\n",
    "config['forward_model_params']['operations']['fwd_mask_noise'] = False\n",
    "model = train.get_model(config, device=device)\n",
    "model.eval()\n",
    "fm, rm = model.model1, model.model2\n",
    "\n",
    "print(fm.passthrough)\n",
    "print(fm.operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_image_learned(image, crop_shape, patch_shape):\n",
    "    image = np.stack(\n",
    "        [diffuser_utils.pyramid_down(image[:crop_shape[0],:crop_shape[1],i],patch_shape) for i in range(image.shape[-1])], 0\n",
    "    )\n",
    "\n",
    "    image = (image - max(0., np.min(image)))\n",
    "    image = image / np.max(image)\n",
    "    image = torch.tensor(image)[None, None,...]\n",
    "    return image\n",
    "\n",
    "def patchwise_predict_image_learned(image : torch.Tensor, model):\n",
    "    patchy, patchx  = model.model1.psfs.shape[-2:] \n",
    "    patch_centers = stitch_utils.get_overlapping_positions(\n",
    "        (image.shape[-2]//2, image.shape[-1]//2), \n",
    "        image.shape[-2:],\n",
    "        (patchy, patchx),\n",
    "        min_overlap=64 # The higher this is, the less edge artifacts may show up\n",
    "    )\n",
    "\n",
    "\n",
    "    prediction = np.zeros(image.squeeze().shape)\n",
    "    contributions_mask = np.zeros(image.shape[-2:])\n",
    "    for i, (ceny, cenx) in enumerate(patch_centers):\n",
    "        reg = [ceny - patchy//2, ceny + patchy//2, cenx - patchx//2, cenx + patchx//2]\n",
    "        patch_gt = image[..., reg[0]:reg[1], reg[2]:reg[3]]\n",
    "        sim = model.model1(patch_gt.to(device))\n",
    "        pred = model.model2((sim- sim.mean()) / sim.std()).detach().cpu().numpy()\n",
    "        pred = pred*patch_gt.std().numpy() + patch_gt.mean().numpy()\n",
    "\n",
    "        # ------------ REMOVE NON IMAGE-BORDERING PATCH EDGE ARTIFACTS ----------- #\n",
    "        crop_width = pred.shape[-1]//10 # assuming patch is square\n",
    "\n",
    "        # Crop patch edges that are not bording an image edge\n",
    "        bordering_top = (ceny - patchy // 2 == 0)\n",
    "        bordering_bottom = (ceny + patchy // 2 == image.shape[-2])\n",
    "        bordering_right = (cenx + patchx // 2 == image.shape[-1])\n",
    "        bordering_left = (cenx - patchx // 2 == 0)\n",
    "        if not bordering_top:\n",
    "            pred, reg[0] = pred[..., crop_width:, :], reg[0] + crop_width\n",
    "        if not bordering_bottom:\n",
    "            pred, reg[1] = pred[..., :-crop_width, :], reg[1] - crop_width\n",
    "        if not bordering_left:\n",
    "            pred, reg[2] = pred[..., :, crop_width:], reg[2] + crop_width\n",
    "        if not bordering_right:\n",
    "            pred, reg[3] = pred[..., :, :-crop_width], reg[3] - crop_width\n",
    "\n",
    "\n",
    "        # Insert the cropped patch into the prediction array\n",
    "        prediction[..., reg[0]:reg[1], reg[2]:reg[3]] += pred.squeeze()\n",
    "        contributions_mask[reg[0]:reg[1], reg[2]:reg[3]] += 1\n",
    "    prediction = prediction / contributions_mask\n",
    "    return np.maximum(0, prediction).transpose(1,2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon = patchwise_predict_image_learned(harvard_bushes_gt, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savename = os.path.join(config[\"save_recon_path\"], f\"harvard_bushes_learned_recon_learned_condunet_L1psf_L1mask_3meas\")\n",
    "save_image_fc_npy(recon, savename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon = patchwise_predict_image_learned(fruit_artichoke_gt, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savename = os.path.join(config[\"save_recon_path\"], f\"fruit_artichoke_learned_recon_learned_condunet_L1psf_L1mask_3meas\")\n",
    "save_image_fc_npy(recon, savename, fc_range=(400,780))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon = patchwise_predict_image_learned(icvl_color_checker_gt, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savename = os.path.join(config[\"save_recon_path\"], f\"icvl_color_checker_learned_recon_learned_condunet_L1psf_L1mask_3meas\")\n",
    "save_image_fc_npy(recon, savename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon = patchwise_predict_image_learned(kaist_img_gt, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savename = os.path.join(config[\"save_recon_path\"], f\"kaist_scene03_learned_recon_learned_condunet_L1psf_L1mask_3meas\")\n",
    "save_image_fc_npy(recon, savename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HANDSHAKE RECONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handshake_config = \"/home/cfoley/SpectralDefocusCam/notebooks/figure_generation/handshake_random_config.yml\"\n",
    "config = helper.read_config(handshake_config)\n",
    "model = train.get_model(config, device=device)\n",
    "fm, rm = model.model1, model.model2\n",
    "\n",
    "rm.L /= 10\n",
    "rm.iters = 151\n",
    "rm.print_every = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = fm(harvard_bushes_gt.to(device))\n",
    "rm(sim.squeeze(dim=(0,2)))\n",
    "recon = rm.out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savename = os.path.join(config[\"save_recon_path\"], f\"harvard_bushes_handshake_fista_recon_{rm.psfs.shape[0]}_{rm.tv_lambda}_{rm.tv_lambdaw}_{rm.tv_lambdax}\")\n",
    "save_image_fc_npy(recon, savename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = fm(fruit_artichoke_gt.to(device))\n",
    "rm(sim.squeeze(dim=(0,2)))\n",
    "recon = rm.out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savename = os.path.join(config[\"save_recon_path\"], f\"fruit_artichoke_handshake_fista_recon_{rm.psfs.shape[0]}_{rm.tv_lambda}_{rm.tv_lambdaw}_{rm.tv_lambdax}\")\n",
    "save_image_fc_npy(recon, savename, fc_range=(400,780))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = fm(icvl_color_checker_gt.to(device))\n",
    "rm(sim.squeeze(dim=(0,2)))\n",
    "recon = rm.out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savename = os.path.join(config[\"save_recon_path\"], f\"icvl_colorpalette_handshake_fista_recon_{rm.psfs.shape[0]}_{rm.tv_lambda}_{rm.tv_lambdaw}_{rm.tv_lambdax}\")\n",
    "save_image_fc_npy(recon, savename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = fm(kaist_img_gt.to(device))\n",
    "rm(sim.squeeze(dim=(0,2)))\n",
    "recon = rm.out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savename = os.path.join(config[\"save_recon_path\"], f\"kaist_scene03_handshake_fista_recon_{rm.psfs.shape[0]}_{rm.tv_lambda}_{rm.tv_lambdaw}_{rm.tv_lambdax}\")\n",
    "save_image_fc_npy(recon, savename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIFFUSER RECONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handshake_config = \"/home/cfoley/SpectralDefocusCam/notebooks/figure_generation/diffuser_config.yml\"\n",
    "config = helper.read_config(handshake_config)\n",
    "model = train.get_model(config, device=device)\n",
    "fm, rm = model.model1, model.model2\n",
    "\n",
    "rm.L /= 5\n",
    "rm.print_every = 80\n",
    "rm.plot = True\n",
    "rm.iters = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = fm(harvard_bushes_gt.to(device))\n",
    "rm(sim.squeeze(dim=(0,2)))\n",
    "recon = rm.out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savename = os.path.join(config[\"save_recon_path\"], f\"harvard_bushes_diffuser_fista_recon_{rm.psfs.shape[0]}_{rm.tv_lambda}_{rm.tv_lambdaw}_{rm.tv_lambdax}\")\n",
    "save_image_fc_npy(recon, savename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = fm(fruit_artichoke_gt.to(device))\n",
    "rm(sim.squeeze(dim=(0,2)))\n",
    "recon = rm.out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savename = os.path.join(config[\"save_recon_path\"], f\"fruit_artichoke_diffuser_fista_recon_{rm.psfs.shape[0]}_{rm.tv_lambda}_{rm.tv_lambdaw}_{rm.tv_lambdax}\")\n",
    "save_image_fc_npy(recon, savename, fc_range=(400,780))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = fm(icvl_color_checker_gt.to(device))\n",
    "rm(sim.squeeze(dim=(0,2)))\n",
    "recon = rm.out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savename = os.path.join(config[\"save_recon_path\"], f\"icvl_colorpalette_diffuser_fista_recon_{rm.psfs.shape[0]}_{rm.tv_lambda}_{rm.tv_lambdaw}_{rm.tv_lambdax}\")\n",
    "save_image_fc_npy(recon, savename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = fm(kaist_img_gt.to(device))\n",
    "rm(sim.squeeze(dim=(0,2)))\n",
    "recon = rm.out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savename = os.path.join(config[\"save_recon_path\"], f\"kaist_scene03_diffuser_fista_recon_{rm.psfs.shape[0]}_{rm.tv_lambda}_{rm.tv_lambdaw}_{rm.tv_lambdax}\")\n",
    "save_image_fc_npy(recon, savename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchjax_310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
